项目目标：
	实现一个性能尽量高的分布式内网全文搜索引擎
	
	爬虫(Reptile)
		内部框架：
			Reptile/
				Reptile.so
					主程序，负责多线程及其他方面的配置
				urlist.so
					主程序	负责对怕取过程中，内存中url的管理
				communicator.so
					主程序	负责分布式方面的操作
					
				config.py
					主程序	负责相关配置
				intermit.so
					主程序	负责对断点的保存和
		外部接口：
			Saver.save()
				将爬虫爬取的结果进行存储
				用户可以选择将爬取的结果存储到数据库或其他。
                为了能够方便处理，依旧存储为xml格式
			Judger.judge()
				对新得到的url进行判断，是否加入到url池中
---------------------------------------------------
要点：
    考虑插入式索引文件编写
    刚开始没n个文件编译为一个tem文件 之后对tem文件同一用外排序同一保存为一个ind文件
    最终查询时，也尽量采用动态载入内存查找的方式
    
    动态索引插入：
        存储tem文件，或者外部排序的中间过程 将不需要修改的部分直接参与编译，将新部分插入其中



    解析索引库(Parser) 
        内部框架:
            Parser/
                config.py
                io.py
                    对外文件数据存取接口
                    传入xml文件
                lib/
                   Thesaurus.pyx
                        词库
                   Indexer.pyx
                        索引库


开发日志:
    01-12:爬虫开端
    01-13:爬虫开端 开始制作saver 和 judger 部分
    01-14:爬虫开端 设计数据库结构，完善saver
    01-15:爬虫中间 编写Communitor分布式计算库，处理很多线程间同步问题
    01-16:爬虫攻坚 Communitor分布式计算库，发送模块
    01-17:爬虫攻坚 Communitor分布式计算库，API设计编写
    01-19:解析库开端 词库相关库编写[Thesaurus.pyx] 
    01-20:索引库编写 [Indexer.pyx]
